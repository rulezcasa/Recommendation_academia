{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bcrypt\n",
    "from pymongo import MongoClient\n",
    "import ssl\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e662273",
   "metadata": {},
   "source": [
    "  ## Importing the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8032b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141120ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 0','_id','password','Timestamp'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec87ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a69f68",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable SSL verification\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c5def",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing out stopwords in english\n",
    "x=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3708d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def general_preprocess(to_preprocess_column_name, df_name):\n",
    "    to_preprocess_column_name_processed = []\n",
    "    lemma = WordNetLemmatizer()\n",
    "    \n",
    "    for i in range(len(df_name)):\n",
    "        col = df_name.iloc[i][to_preprocess_column_name]\n",
    "        col = re.sub('[^a-zA-Z]', ' ', col)  # Remove non-alphabetic characters\n",
    "        col = col.lower()  # Convert to lowercase\n",
    "        col = col.split()  # Split into words\n",
    "        col = [lemma.lemmatize(word) for word in col if word not in set(stopwords.words('english'))]  # Lemmatize and remove stopwords\n",
    "        col = ' '.join(col)  # Join words back into a single string\n",
    "        to_preprocess_column_name_processed.append(col)\n",
    "    \n",
    "    return to_preprocess_column_name_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168647c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic_preprocessed=general_preprocess('Topic',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c38e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe68593",
   "metadata": {},
   "outputs": [],
   "source": [
    "Skills_preprocessed=general_preprocess('Skills',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Skills_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b07ab89",
   "metadata": {},
   "source": [
    "## Combining target columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4784ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = pd.DataFrame({\n",
    "    'Skills': Skills_preprocessed,\n",
    "    'Topic': Topic_preprocessed\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Combined'] = data['Skills'] + ', ' + data['Topic']\n",
    "\n",
    "# Drop the individual columns if you only need the combined column\n",
    "df_combined = data.drop(columns=['Skills', 'Topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8daedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177cfbf",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebbd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=df_combined['Combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e732be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(train_data)\n",
    "\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef76b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd39ea7",
   "metadata": {},
   "source": [
    "## Affinity clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e517d1be",
   "metadata": {},
   "source": [
    "Affinity Propagation is a clustering algorithm that does not require the number of clusters to be specified in advance. It works by passing messages between data points to identify clusters of similar items(similarity matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072fb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "# Step 3: Apply Affinity Propagation\n",
    "affinity_propagation = AffinityPropagation(affinity='precomputed', random_state=42)\n",
    "labels = affinity_propagation.fit_predict(cosine_sim_matrix)\n",
    "\n",
    "# Step 4: Create a DataFrame to view results\n",
    "df = pd.DataFrame({'Skillset': train_data, 'Cluster': labels})\n",
    "\n",
    "# Print the DataFrame with clusters\n",
    "print(\"Clustered Skillsets with Affinity Propagation:\")\n",
    "print(df)\n",
    "\n",
    "# Print the number of items in each cluster\n",
    "cluster_counts = df['Cluster'].value_counts().sort_index()\n",
    "print(\"\\nNumber of Items in Each Cluster:\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the number of data in each cluster\n",
    "cluster_counts = df['Cluster'].value_counts().sort_index()\n",
    "print(\"\\nNumber of Items in Each Cluster:\")\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63fab0",
   "metadata": {},
   "source": [
    "## dimensionality r(TSNE) reduction and visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb7e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "reduced_matrix = tsne.fit_transform(tfidf_matrix.toarray())\n",
    "\n",
    "# Add t-SNE results to DataFrame\n",
    "df_tsne = pd.DataFrame(reduced_matrix, columns=['TSNE1', 'TSNE2'])\n",
    "df_tsne['Cluster'] = labels\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='TSNE1', y='TSNE2', hue='Cluster', data=df_tsne, palette='viridis', marker='o', s=100)\n",
    "plt.title('Clusters Visualized with t-SNE')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.savefig('tf_idf_cluster.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()  # Automatically adjusts subplot parameters to give specified padding\n",
    "\n",
    "# Save the plot with 600 DPI resolution\n",
    "plt.savefig('tf_idf_cluster.png', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826f69f",
   "metadata": {},
   "source": [
    "## Checking specific cluster values and their data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1099eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = df[df['Cluster'] == 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523191d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288414f5",
   "metadata": {},
   "source": [
    "## Intra cluster similarities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to hold intra-cluster similarities\n",
    "intra_cluster_similarities = []\n",
    "\n",
    "# Get unique cluster labels\n",
    "unique_clusters = np.unique(labels)\n",
    "\n",
    "for cluster in unique_clusters:\n",
    "    # Get the indices of the data points in the current cluster\n",
    "    cluster_indices = np.where(labels == cluster)[0]\n",
    "    \n",
    "    if len(cluster_indices) > 1:  # Only compute if more than one point\n",
    "        # Extract the TF-IDF matrix for the current cluster\n",
    "        cluster_tfidf_matrix = tfidf_matrix[cluster_indices]\n",
    "        \n",
    "        # Compute the cosine similarity matrix for the current cluster\n",
    "        cluster_sim_matrix = cosine_similarity(cluster_tfidf_matrix)\n",
    "        \n",
    "        # Get the number of points in the cluster\n",
    "        num_points = len(cluster_indices)\n",
    "        \n",
    "        # Compute the average similarity within the cluster\n",
    "        # Exclude the diagonal (self-similarity) from the average\n",
    "        avg_similarity = (np.sum(cluster_sim_matrix) - num_points) / (num_points * (num_points - 1))\n",
    "        \n",
    "        intra_cluster_similarities.append(avg_similarity)\n",
    "    else:\n",
    "        # Not enough points to calculate\n",
    "        intra_cluster_similarities.append(np.nan)\n",
    "\n",
    "# Calculate the overall intra-cluster similarity\n",
    "# Filter out NaN values (clusters with only one point)\n",
    "valid_similarities = [sim for sim in intra_cluster_similarities if not np.isnan(sim)]\n",
    "overall_intra_cluster_similarity = np.mean(valid_similarities) if valid_similarities else np.nan\n",
    "\n",
    "# Print the overall intra-cluster similarity\n",
    "print(f\"\\nOverall Intra-Cluster Similarity: {overall_intra_cluster_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b69fa42",
   "metadata": {},
   "source": [
    "## Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50735cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Assuming `embeddings` is your feature matrix and `labels` are your cluster labels\n",
    "silhouette_avg = silhouette_score(tfidf_matrix, labels)\n",
    "\n",
    "# Print the Silhouette Score\n",
    "print(f\"Silhouette Score: {silhouette_avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aafa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "# Convert sparse matrix to dense\n",
    "tfidf_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# Compute the Davies-Bouldin Index\n",
    "dbi = davies_bouldin_score(tfidf_dense, labels)\n",
    "\n",
    "# Print the Davies-Bouldin Index\n",
    "print(f\"Davies-Bouldin Index: {dbi:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5bb85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Combined'] = df['Skillset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cluster']=df['Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa14e4",
   "metadata": {},
   "source": [
    "## Recommendation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ca7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_profiles_by_topic_skills(user_index, df, top_n):\n",
    "    \"\"\"\n",
    "    Recommends the top N profiles to a target profile based on 'Topic' and 'Skills' columns.\n",
    "\n",
    "    Parameters:\n",
    "    - user_index (int): The index of the target profile in the DataFrame.\n",
    "    - df (pandas.DataFrame): The DataFrame containing profile data.\n",
    "    - top_n (int): The number of top profiles to recommend.\n",
    "\n",
    "    Returns:\n",
    "    - list of tuples: Each tuple contains the index and similarity score of a recommended profile.\n",
    "    \"\"\"\n",
    "    # Combine 'Topic' and 'Skills' into a single text representation for each profile\n",
    "    \n",
    "    # Create a TF-IDF vectorizer and transform the combined text data\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(data['Combined'])\n",
    "    \n",
    "    # Get the TF-IDF vector for the target profile\n",
    "    target_vector = tfidf_matrix[user_index]\n",
    "    \n",
    "    # Compute cosine similarities between the target profile and all other profiles\n",
    "    similarities = cosine_similarity(target_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Exclude the target profile itself by setting its similarity score to -1\n",
    "    similarities[user_index] = -1\n",
    "    \n",
    "    # Get the indices of the top N most similar profiles\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    # Create a list of tuples with index and similarity score\n",
    "    recommendations = [(idx, similarities[idx]) for idx in top_indices]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "def print_profile_details(profile_index, df):\n",
    "    \"\"\"\n",
    "    Prints the details of a specific profile.\n",
    "\n",
    "    Parameters:\n",
    "    - profile_index (int): The index of the profile in the DataFrame.\n",
    "    - df (pandas.DataFrame): The DataFrame containing profile data.\n",
    "    \"\"\"\n",
    "    profile_details = df.iloc[profile_index]\n",
    "    print(f\"Details of Target Profile (Index: {profile_index}):\")\n",
    "    print(f\"Name: {profile_details['Name']}\")\n",
    "    print(f\"Email: {profile_details['Email']}\")\n",
    "    print(f\"Skills: {profile_details['Skills']}\")\n",
    "    print(f\"Domain Interest: {profile_details['Topic']}\")\n",
    "    print(f\"Cluster: {profile_details['Cluster']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "\n",
    "def print_recommendation_details(recommendations, df):\n",
    "    \"\"\"\n",
    "    Prints the details of the recommended profiles.\n",
    "\n",
    "    Parameters:\n",
    "    - recommendations (list of tuples): Each tuple contains the index and similarity score of a recommended profile.\n",
    "    - df (pandas.DataFrame): The DataFrame containing profile data.\n",
    "    \"\"\"\n",
    "    for idx, score in recommendations:\n",
    "        profile_details = data.iloc[idx]\n",
    "        print(f\"Index: {idx}\")\n",
    "        print(f\"Similarity Score: {score:.4f}\")\n",
    "        print(f\"Name: {profile_details['Name']}\")\n",
    "        print(f\"Email: {profile_details['Email']}\")\n",
    "        print(f\"Skills: {profile_details['Skills']}\")\n",
    "        print(f\"Domain Interest: {profile_details['Topic']}\")\n",
    "        print(f\"Cluster: {profile_details['Cluster']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "target_profile_index = 575  # Replace with the index of the target profile\n",
    "print_profile_details(target_profile_index, data)\n",
    "top_n_recommendations = recommend_profiles_by_topic_skills(target_profile_index, data, top_n=10)\n",
    "print_recommendation_details(top_n_recommendations, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_for_all_profiles(df, top_n=10, similarity_threshold=0.90):\n",
    "    \"\"\"\n",
    "    Calculate the precision across all profiles based on a similarity threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame containing profile data.\n",
    "    - top_n (int): The number of top profiles to recommend.\n",
    "    - similarity_threshold (float): The threshold above which a profile is considered relevant.\n",
    "\n",
    "    Returns:\n",
    "    - float: Average precision across all profiles.\n",
    "    \"\"\"\n",
    "    total_precision = 0\n",
    "    count_profiles = len(df)  # Count of total profiles to iterate over\n",
    "\n",
    "    for user_index in range(count_profiles):\n",
    "        # Get top N recommendations for the current profile\n",
    "        recommendations = recommend_profiles_by_topic_skills(user_index, df, top_n)\n",
    "\n",
    "        # Extract similarity scores\n",
    "        similarity_scores = [score for idx, score in recommendations]\n",
    "\n",
    "        # Count how many recommended profiles are above the similarity threshold\n",
    "        relevant_recommendations = sum(score >= similarity_threshold for score in similarity_scores)\n",
    "\n",
    "        # Calculate precision for this profile\n",
    "        precision = relevant_recommendations / top_n if top_n > 0 else 0\n",
    "        \n",
    "        # Accumulate the precision for averaging later\n",
    "        total_precision += precision\n",
    "\n",
    "    # Calculate average precision\n",
    "    average_precision = total_precision / count_profiles if count_profiles > 0 else 0\n",
    "    return average_precision\n",
    "\n",
    "# Example Usage\n",
    "final_precision = calculate_precision_for_all_profiles(data)\n",
    "print(f\"Final Average Precision across all profiles: {final_precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def generate_keyword_cloud(df, column, title):\n",
    "    \"\"\"\n",
    "    Generates and plots a word cloud for a specific column in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame containing profile data.\n",
    "    - column (str): The column name for which the word cloud is to be generated.\n",
    "    - title (str): The title for the word cloud plot.\n",
    "    \"\"\"\n",
    "    # Combine all text in the specified column\n",
    "    text = \" \".join(df[column].dropna().astype(str).values)\n",
    "    \n",
    "    # Generate the word cloud\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    \n",
    "    # Plot the word cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Generate and plot the keyword cloud for 'Skills'\n",
    "generate_keyword_cloud(data, 'Skills', 'Keyword Cloud for Skills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41edc9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
